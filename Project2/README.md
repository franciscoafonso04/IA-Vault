# 🧠 IART Project 2 – Mental Health Classification

This repository contains the second assignment for the Artificial Intelligence and Reasoning Techniques (IART) course at FEUP (2024/25). The objective was to train and evaluate machine learning models to predict symptoms of depression based on personal, academic, and lifestyle data.

📌 **Grade received: 18.0/20**

---

## 📁 Files Included

- `mental_health_A2_77.ipynb` — Complete Jupyter notebook with:
  - Exploratory Data Analysis (EDA)
  - Preprocessing and feature selection
  - Model training (Decision Tree, Logistic Regression, Random Forest, MLPClassifier)
  - Hyperparameter tuning
  - Evaluation using accuracy, F1 score and confusion matrix
  - Final prediction and export of results
- `IART2.pdf` — 10-slide presentation summarizing the project
- `train.csv` — Original training dataset
- `test.csv` — Original test dataset
- `result.csv` — Final predictions generated by the tuned MLPClassifier

---

## ▶️ How to Run

1. Open `mental_health_A2_77.ipynb` in a Jupyter environment (e.g., Jupyter Notebook or VS Code with Jupyter extension).
2. Make sure all `.csv` files are in the same directory as the notebook.
3. Run all cells in order:
   - The notebook performs preprocessing, training, hyperparameter tuning, and evaluation.
   - The final section applies the model to the test set and generates `result.csv`.

📦 Required libraries:
- `pandas`
- `numpy`
- `scikit-learn`
- `matplotlib`

You can install them using:

```bash
pip install pandas numpy scikit-learn matplotlib
````

---

## 📊 Dataset

The dataset used is from the Kaggle competition:
[Playground Series – Season 4, Episode 11](https://www.kaggle.com/competitions/playground-series-s4e11)

It contains anonymized data related to individuals’ demographics, education, and lifestyle habits, with the goal of predicting depression symptoms.

---

## ✍️ Authors

* Francisco Afonso (up202208115)
* Miguel Caseira (up202207678)
* Pedro Santos (up202205900)

---

## 🏁 Result Summary

The final model chosen was a **tuned MLPClassifier**, which achieved:

* **Accuracy**: 0.93
* **F1 Score**: 0.81

The notebook also compares various models and tuning strategies, highlighting trade-offs in performance and computation.

