# ğŸ§  IART Project 2 â€“ Mental Health Classification

This repository contains the second assignment for the Artificial Intelligence and Reasoning Techniques (IART) course at FEUP (2024/25). The objective was to train and evaluate machine learning models to predict symptoms of depression based on personal, academic, and lifestyle data.

ğŸ“Œ **Grade received: 18.0/20**

---

## ğŸ“ Files Included

- `mental_health_A2_77.ipynb` â€” Complete Jupyter notebook with:
  - Exploratory Data Analysis (EDA)
  - Preprocessing and feature selection
  - Model training (Decision Tree, Logistic Regression, Random Forest, MLPClassifier)
  - Hyperparameter tuning
  - Evaluation using accuracy, F1 score and confusion matrix
  - Final prediction and export of results
- `IART2.pdf` â€” 10-slide presentation summarizing the project
- `train.csv` â€” Original training dataset
- `test.csv` â€” Original test dataset
- `result.csv` â€” Final predictions generated by the tuned MLPClassifier

---

## â–¶ï¸ How to Run

1. Open `mental_health_A2_77.ipynb` in a Jupyter environment (e.g., Jupyter Notebook or VS Code with Jupyter extension).
2. Make sure all `.csv` files are in the same directory as the notebook.
3. Run all cells in order:
   - The notebook performs preprocessing, training, hyperparameter tuning, and evaluation.
   - The final section applies the model to the test set and generates `result.csv`.

ğŸ“¦ Required libraries:
- `pandas`
- `numpy`
- `scikit-learn`
- `matplotlib`

You can install them using:

```bash
pip install pandas numpy scikit-learn matplotlib
````

---

## ğŸ“Š Dataset

The dataset used is from the Kaggle competition:
[Playground Series â€“ Season 4, Episode 11](https://www.kaggle.com/competitions/playground-series-s4e11)

It contains anonymized data related to individualsâ€™ demographics, education, and lifestyle habits, with the goal of predicting depression symptoms.

---

## âœï¸ Authors

* Francisco Afonso (up202208115)
* Miguel Caseira (up202207678)
* Pedro Santos (up202205900)

---

## ğŸ Result Summary

The final model chosen was a **tuned MLPClassifier**, which achieved:

* **Accuracy**: 0.93
* **F1 Score**: 0.81

The notebook also compares various models and tuning strategies, highlighting trade-offs in performance and computation.

